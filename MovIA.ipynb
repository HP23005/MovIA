{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b589171-1a90-45df-8d05-5dc45227c1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kagglehub in c:\\users\\ivan\\anaconda3\\lib\\site-packages (0.3.10)\n",
      "Requirement already satisfied: packaging in c:\\users\\ivan\\anaconda3\\lib\\site-packages (from kagglehub) (24.1)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\ivan\\anaconda3\\lib\\site-packages (from kagglehub) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\ivan\\anaconda3\\lib\\site-packages (from kagglehub) (2.32.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\ivan\\anaconda3\\lib\\site-packages (from kagglehub) (4.66.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ivan\\anaconda3\\lib\\site-packages (from requests->kagglehub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ivan\\anaconda3\\lib\\site-packages (from requests->kagglehub) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ivan\\anaconda3\\lib\\site-packages (from requests->kagglehub) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ivan\\anaconda3\\lib\\site-packages (from requests->kagglehub) (2025.1.31)\n",
      "Requirement already satisfied: colorama in c:\\users\\ivan\\anaconda3\\lib\\site-packages (from tqdm->kagglehub) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b898f0b-d195-422e-a096-74bd10332faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\ivan\\.cache\\kagglehub\\datasets\\netflix-inc\\netflix-prize-data\\versions\\2\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"netflix-inc/netflix-prize-data\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "874b389d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\ivan\\anaconda3\\lib\\site-packages (2.2.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\ivan\\anaconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ivan\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ivan\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ivan\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ivan\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9179fab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: unidecode in c:\\users\\ivan\\anaconda3\\lib\\site-packages (1.3.8)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "07b876d3-fe85-423e-aef4-e55c49373af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from unidecode import unidecode\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "635b4cf9-38d7-46d5-bce6-923f257fee80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para limpiar texto\n",
    "def limpiar_texto(texto):\n",
    "    if isinstance(texto, str):\n",
    "        texto = unidecode(texto)  # Remueve tildes y caracteres especiales\n",
    "        texto = re.sub(r\"[^\\w\\s]\", \"\", texto)  # Elimina signos de puntuación\n",
    "        texto = re.sub(r\"\\s+\", \" \", texto).strip()  # Espacios extra\n",
    "    return texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e4be379-a03b-44ee-8ea6-8f459f391fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se alcanzó el límite: movie_id 250. Finalizando.\n",
      "Archivo de calificaciones guardado en CSV sin problemas de memoria.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    "\n",
    "rating_files = glob(\"C:/Users/ivan/.cache/kagglehub/datasets/netflix-inc/netflix-prize-data/versions/2/combined_data_*.txt\")\n",
    "\n",
    "output_file = \"netflix_ratings_clean.csv\"\n",
    "max_movie_id = 250  # Límite de películas a procesar\n",
    "\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as out_file:\n",
    "    out_file.write(\"movie_id,user_id,rating,date\\n\")  # Escribir encabezados\n",
    "\n",
    "    for file in rating_files:\n",
    "        movie_id = None\n",
    "        with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if line.endswith(\":\"):\n",
    "                    movie_id = int(line[:-1])\n",
    "                    \n",
    "                    # Detener el procesamiento si se supera el límite\n",
    "                    if movie_id > max_movie_id:\n",
    "                        print(f\"Se alcanzó el límite: movie_id {max_movie_id}. Finalizando.\")\n",
    "                        break\n",
    "                else:\n",
    "                    if movie_id is not None and movie_id <= max_movie_id:\n",
    "                        try:\n",
    "                            user_id, rating, date = line.split(\",\")\n",
    "                            out_file.write(f\"{movie_id},{user_id},{rating},{date}\\n\")\n",
    "                        except ValueError:\n",
    "                            print(f\"Error al procesar línea: {line}\")\n",
    "\n",
    "        # Si se alcanzó el límite, salir del loop principal\n",
    "        if movie_id and movie_id > max_movie_id:\n",
    "            break  \n",
    "\n",
    "print(\"Archivo de calificaciones guardado en CSV sin problemas de memoria.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5be05f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeras 10 filas del DataFrame:\n",
      "   movie_id  user_id  rating        date\n",
      "0         1  1488844       3  2005-09-06\n",
      "1         1   822109       5  2005-05-13\n",
      "2         1   885013       4  2005-10-19\n",
      "3         1    30878       4  2005-12-26\n",
      "4         1   823519       3  2004-05-03\n",
      "5         1   893988       3  2005-11-17\n",
      "6         1   124105       4  2004-08-05\n",
      "7         1  1248029       3  2004-04-22\n",
      "8         1  1842128       4  2004-05-09\n",
      "9         1  2238063       3  2005-05-11\n",
      "\n",
      "El archivo tiene un total de 1,573,342 filas.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Archivo de calificaciones procesado\n",
    "file_path = \"netflix_ratings_clean.csv\"\n",
    "\n",
    "# Definir el tamaño del chunk\n",
    "chunk_size = 500000\n",
    "\n",
    "# Contador de filas totales\n",
    "total_rows = 0\n",
    "\n",
    "# Leer el primer chunk para mostrarlo como DataFrame\n",
    "first_chunk = next(pd.read_csv(file_path, chunksize=chunk_size))\n",
    "\n",
    "# Mostrar las primeras 10 filas como DataFrame\n",
    "print(\"Primeras 10 filas del DataFrame:\")\n",
    "print(first_chunk.head(10))\n",
    "\n",
    "# Calcular el número total de filas sumando los tamaños de los chunks\n",
    "for chunk in pd.read_csv(file_path, chunksize=chunk_size):\n",
    "    total_rows += len(chunk)\n",
    "\n",
    "# Sumar las filas del primer chunk\n",
    "total_rows += len(first_chunk)\n",
    "\n",
    "print(f\"\\nEl archivo tiene un total de {total_rows:,} filas.\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c883b3e7-e2c0-4b6e-9ea3-1d0309a4bf71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo de títulos de películas procesado y guardado.\n"
     ]
    }
   ],
   "source": [
    "# Cargar archivo de películas\n",
    "df_movies = pd.read_csv(\"C:/Users/ivan/.cache/kagglehub/datasets/netflix-inc/netflix-prize-data/versions/2/movie_titles.csv\", \n",
    "                        encoding=\"latin1\", header=None, names=[\"movie_id\", \"year\", \"title\"], delimiter=\",\", on_bad_lines='skip')\n",
    "\n",
    "# Filtrar solo hasta movie_id 250\n",
    "df_movies = df_movies[df_movies['movie_id'] <= 250]\n",
    "\n",
    "# Rellenar los valores NaN en la columna 'year' con 0 y convertir a entero\n",
    "df_movies['year'] = df_movies['year'].fillna(0)\n",
    "df_movies['year'] = df_movies['year'].astype(int)\n",
    "\n",
    "# Limpiar los títulos de películas (necesitas la función limpiar_texto definida)\n",
    "df_movies[\"title\"] = df_movies[\"title\"].apply(limpiar_texto)\n",
    "\n",
    "# Guardar el archivo limpio\n",
    "df_movies.to_csv(\"movie_titles_clean.csv\", index=False)\n",
    "\n",
    "print(\"Archivo de títulos de películas procesado y guardado.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0441c6d6-64d4-4086-8b45-215f5d6b0999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   movie_id  year                       title\n",
      "0         1  2003             Dinosaur Planet\n",
      "1         2  2004  Isle of Man TT 2004 Review\n",
      "2         3  1997                   Character\n",
      "3         4  1994   Paula Abduls Get Up Dance\n",
      "4         5  2004    The Rise and Fall of ECW\n",
      "5         6  1997                        Sick\n",
      "6         7  1992                       8 Man\n",
      "7         8  2004         What the Do We Know\n",
      "8         9  1991     Class of Nuke Em High 2\n",
      "9        10  2001                     Fighter\n",
      "(249, 3)\n"
     ]
    }
   ],
   "source": [
    "print(df_movies.head(10))\n",
    "print(df_movies.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "f7b4829a-c2d5-41dd-a4f1-93db1fc6dae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo final con títulos de películas y rating promedio guardado correctamente.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar archivo de películas\n",
    "df_movies = pd.read_csv(\"movie_titles_clean.csv\")\n",
    "\n",
    "# Cargar archivo de ratings\n",
    "df_ratings = pd.read_csv(\"netflix_ratings_clean.csv\")\n",
    "\n",
    "# Calcular el rating promedio por película\n",
    "avg_ratings = df_ratings.groupby('movie_id')['rating'].mean().reset_index()\n",
    "avg_ratings.columns = ['movie_id', 'avg_rating']  # Renombrar columna para el rating promedio\n",
    "\n",
    "# Hacer el merge para agregar el título de la película y el rating promedio\n",
    "df_final = pd.merge(df_movies[['movie_id', 'title']], avg_ratings, on='movie_id', how='inner')\n",
    "\n",
    "# Eliminar posibles duplicados\n",
    "df_final = df_final.drop_duplicates(subset=['movie_id'])\n",
    "\n",
    "# Archivo de salida\n",
    "output_file_final = \"netflix_ratings_with_avg_titles.csv\"\n",
    "\n",
    "# Guardar el archivo con las columnas 'movie_id', 'title' y 'avg_rating'\n",
    "df_final.to_csv(output_file_final, index=False, columns=['movie_id', 'title', 'avg_rating'])\n",
    "\n",
    "print(\"Archivo final con títulos de películas y rating promedio guardado correctamente.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da2ec1e3-e1be-4d32-be96-607545f3dc38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['movie_id', 'title', 'avg_rating'], dtype='object')\n",
      "   movie_id                       title  avg_rating\n",
      "0         1             Dinosaur Planet    3.749543\n",
      "1         2  Isle of Man TT 2004 Review    3.558621\n",
      "2         3                   Character    3.641153\n",
      "3         4   Paula Abduls Get Up Dance    2.739437\n",
      "4         5    The Rise and Fall of ECW    3.919298\n",
      "5         6                        Sick    3.084396\n",
      "6         7                       8 Man    2.129032\n",
      "7         8         What the Do We Know    3.189805\n",
      "8         9     Class of Nuke Em High 2    2.621053\n",
      "9        10                     Fighter    3.180723\n",
      "Total de filas: 249\n"
     ]
    }
   ],
   "source": [
    "df_final = pd.read_csv(\"netflix_ratings_with_avg_titles.csv\")\n",
    "\n",
    "print(df_final.columns)\n",
    "print(df_final.head(10))\n",
    "print(\"Total de filas:\", len(df_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2aeec098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\ivan\\anaconda3\\lib\\site-packages (3.8.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\ivan\\anaconda3\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\ivan\\anaconda3\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\ivan\\anaconda3\\lib\\site-packages (from spacy) (1.0.12)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\ivan\\anaconda3\\lib\\site-packages (from spacy) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\ivan\\anaconda3\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in c:\\users\\ivan\\anaconda3\\lib\\site-packages (from spacy) (8.3.4)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\ivan\\anaconda3\\lib\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\ivan\\anaconda3\\lib\\site-packages (from spacy) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\ivan\\anaconda3\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\ivan\\anaconda3\\lib\\site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\ivan\\anaconda3\\lib\\site-packages (from spacy) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\ivan\\anaconda3\\lib\\site-packages (from spacy) (4.66.5)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\ivan\\anaconda3\\lib\\site-packages (from spacy) (1.26.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\ivan\\anaconda3\\lib\\site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\ivan\\anaconda3\\lib\\site-packages (from spacy) (2.8.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ivan\\anaconda3\\lib\\site-packages (from spacy) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ivan\\anaconda3\\lib\\site-packages (from spacy) (75.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ivan\\anaconda3\\lib\\site-packages (from spacy) (24.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\ivan\\anaconda3\\lib\\site-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\ivan\\anaconda3\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\ivan\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\ivan\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\ivan\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ivan\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ivan\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ivan\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ivan\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.1.31)\n",
      "Requirement already satisfied: blis<1.3.0,>=1.2.0 in c:\\users\\ivan\\anaconda3\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.2.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\ivan\\anaconda3\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\ivan\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\ivan\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\ivan\\anaconda3\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\ivan\\anaconda3\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (5.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ivan\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.1.3)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in c:\\users\\ivan\\anaconda3\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9529425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n"
     ]
    }
   ],
   "source": [
    "import spacy.cli\n",
    "spacy.cli.download(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6b2a67-3a84-4754-9835-5382974d762f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No es necesario realizar la tokenizacion según me comentó la tutora\n",
    "# Trate de reducir los datos por recomendacion de ella para reducir la carga en la memoria\n",
    "# Se debe usar vectorizacion para realizar el sistema de recomendacion de peliculas a los usuarios (TfidfVectorizer)\n",
    "# Hay dos DataFrame uno con movie_id, title, avg_rating\n",
    "# y el segundo que contiene movie_id, user_id, rating, date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8e9904e7-7b31-4143-ad55-bd02b97feda7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión de recomendaciones para el usuario 573537: 100.00%\n",
      "\n",
      "Recomendaciones de películas para el usuario:\n",
      "                    title  avg_rating\n",
      "157  Gentlemen of Fortune    3.932927\n",
      "159             Ninotchka    3.853621\n",
      "0         Dinosaur Planet    3.749543\n",
      "170                  Jack    3.127329\n",
      "158           Gormenghast    3.007786\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Cargar datos\n",
    "ratings_df = pd.read_csv(\"netflix_ratings_clean.csv\")\n",
    "movies_df = pd.read_csv(\"movie_titles_clean.csv\")\n",
    "movies_avg_df = pd.read_csv(\"netflix_ratings_with_avg_titles.csv\")\n",
    "\n",
    "# Crear matriz usuario-película\n",
    "user_matrix = ratings_df.pivot(index=\"user_id\", columns=\"movie_id\", values=\"rating\").fillna(0)\n",
    "\n",
    "# Dividir en entrenamiento y prueba (por ejemplo, el 80% para entrenamiento y 20% para prueba)\n",
    "train_data, test_data = train_test_split(ratings_df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Crear las matrices de usuario-película para entrenamiento y prueba\n",
    "train_matrix = train_data.pivot(index=\"user_id\", columns=\"movie_id\", values=\"rating\").fillna(0)\n",
    "test_matrix = test_data.pivot(index=\"user_id\", columns=\"movie_id\", values=\"rating\").fillna(0)\n",
    "\n",
    "# Entrenar modelo KNN para encontrar usuarios similares según sus calificaciones\n",
    "model_knn = NearestNeighbors(metric=\"cosine\", algorithm=\"brute\")\n",
    "model_knn.fit(train_matrix)\n",
    "\n",
    "# Función para recomendar películas a un usuario con el avg rating\n",
    "def recomendar_peliculas_usuario(user_id, movies_df, movies_avg_df, model_knn, n=5):\n",
    "    # Verificar si el usuario está en el conjunto de entrenamiento\n",
    "    if user_id not in train_matrix.index:\n",
    "        return f\"Usuario {user_id} no encontrado en el conjunto de entrenamiento.\"\n",
    "    \n",
    "    # Encontrar usuarios similares\n",
    "    distances, indices = model_knn.kneighbors([train_matrix.loc[user_id]], n_neighbors=n+1)\n",
    "    similar_users = train_matrix.index[indices.flatten()][1:]  # Omitimos el usuario mismo\n",
    "\n",
    "    # Obtener películas mejor valoradas por los usuarios similares\n",
    "    similar_users_ratings = train_matrix.loc[similar_users].mean(axis=0)  # Promedio de ratings\n",
    "    recommended_movies = similar_users_ratings.sort_values(ascending=False).index[:n]  # Top N películas\n",
    "\n",
    "    # Crear el DataFrame de recomendaciones con el título de la película y su avg rating\n",
    "    recommendations = movies_avg_df[movies_avg_df[\"movie_id\"].isin(recommended_movies)][[\"title\", \"avg_rating\"]]\n",
    "    recommendations = recommendations.sort_values(by=\"avg_rating\", ascending=False)\n",
    "\n",
    "    return recommendations\n",
    "\n",
    "# Función para evaluar precisión (basado en películas recomendadas vs reales)\n",
    "def evaluar_precision(user_id, model_knn, test_matrix, movies_avg_df, n=5):\n",
    "    # Verificar si el usuario está en el conjunto de prueba\n",
    "    if user_id not in test_matrix.index:\n",
    "        return f\"Usuario {user_id} no encontrado en el conjunto de prueba.\"\n",
    "\n",
    "    recommendations = recomendar_peliculas_usuario(user_id, movies_df, movies_avg_df, model_knn, n)\n",
    "    if isinstance(recommendations, str):  # Si el usuario no es encontrado\n",
    "        return recommendations\n",
    "    \n",
    "    # Obtener las películas reales vistas por el usuario en el conjunto de prueba\n",
    "    actual_movies = test_matrix.loc[user_id].dropna().index\n",
    "    recommended_movie_ids = movies_avg_df[movies_avg_df[\"title\"].isin(recommendations['title'])]['movie_id'].values\n",
    "    \n",
    "    # Calcular precisión: cuántas recomendaciones son relevantes (coinciden con las películas reales)\n",
    "    common_movies = np.intersect1d(actual_movies, recommended_movie_ids)\n",
    "    precision = (len(common_movies) / n) * 100  # Multiplicar por 100 para obtener porcentaje\n",
    "    return precision\n",
    "\n",
    "# Evaluación para un usuario específico\n",
    "user_id = 573537\n",
    "\n",
    "# Comprobamos si el usuario está presente en los conjuntos de prueba o entrenamiento antes de evaluar\n",
    "if user_id in test_matrix.index and user_id in train_matrix.index:\n",
    "    precision = evaluar_precision(user_id, model_knn, test_matrix, movies_avg_df, n=5)\n",
    "    print(f\"Precisión de recomendaciones para el usuario {user_id}: {precision:.2f}%\")\n",
    "\n",
    "    # Mostrar las recomendaciones para un usuario\n",
    "    recomendaciones = recomendar_peliculas_usuario(user_id, movies_df, movies_avg_df, model_knn)\n",
    "    print(\"\\nRecomendaciones de películas para el usuario:\")\n",
    "    print(recomendaciones)\n",
    "else:\n",
    "    print(f\"El usuario {user_id} no está presente en los conjuntos de entrenamiento ni de prueba.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cabc49-dfc3-44fd-8fc1-14e450953f2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
